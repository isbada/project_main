{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# 不显示警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------- 全局变量 ------------------------------\n",
    "\n",
    "# TQDM显示选项\n",
    "TQDM = tqdm_notebook\n",
    "\n",
    "# 训练/测试 数据存储路径\n",
    "TRAIN_DIR, TEST_DIR = './train', './test'\n",
    "\n",
    "# 故障标签长度(s)\n",
    "TROUBLE_LEN = 0.5\n",
    "\n",
    "# WINDOW时间长度(s)\n",
    "WINDOW_LEN = 59\n",
    "\n",
    "# 选择使用的特征列表\n",
    "FEAT_SELECT = ['[8:2]', '[6:17]', '[1:7]', '[1:5]',\n",
    "               '[1:20]', '[1:0]', '[1:1]', '[8:4]', '[1:133]']\n",
    "\n",
    "SCALE = StandardScaler()\n",
    "\n",
    "# 指定GPU/CPU参数\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print('DEVICE:', DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------- 数据集类 ------------------------------\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    '''加载数据集的类'''\n",
    "\n",
    "    def __init__(self, root_dir, cls):\n",
    "        '''初始化数据集,主要步骤如下:\n",
    "        1.加载所有的csv表格'''\n",
    "\n",
    "        self.df_l = []\n",
    "        self.samples_all = 0  # 记录产生的sample time series总量\n",
    "        self.samples_l = []  # 记录各个csv数据产生的sample time series长度\n",
    "        for file in TQDM(os.listdir(root_dir), desc='加载%s数据' % cls):\n",
    "            if not file.endswith('.csv'):  # 非csv数据跳过\n",
    "                continue\n",
    "            df_this = pd.read_csv(os.path.join(\n",
    "                root_dir, file)).set_index('Time')[FEAT_SELECT]\n",
    "\n",
    "            df_this = pd.DataFrame(SCALE.fit_transform(\n",
    "                df_this), columns=df_this.columns)\n",
    "\n",
    "            LEN = len(df_this)\n",
    "            # 最后TROUBLE_LEN长度添加上标签1(其余是0),定义为列label\n",
    "            label = np.concatenate([np.zeros(int(LEN - TROUBLE_LEN * 100)),\n",
    "                                    np.ones(int(TROUBLE_LEN * 100))])\n",
    "            df_this['label'] = label.astype(int)\n",
    "            self.df_l.append(df_this)\n",
    "            # 计算本csv数据能够产生的窗口数量\n",
    "            window_num = LEN - WINDOW_LEN * 100 + 1\n",
    "            self.samples_l.append(window_num)\n",
    "            self.samples_all += window_num\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples_all\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 找出两个索引位置\n",
    "        samples_cumsum = np.array(self.samples_l).cumsum()\n",
    "        key1 = np.searchsorted(samples_cumsum, idx + 1)\n",
    "        # 大于第一个cumsum 要减去前面的累加值，否则就是idx\n",
    "        key2 = idx - samples_cumsum[key1 - 1] if key1 > 0 else idx\n",
    "\n",
    "        # 通过key1找到对应的df\n",
    "        target_df = self.df_l[key1]\n",
    "        # 通过key2找到对应的value\n",
    "        df_sample = target_df.iloc[key2: key2 + WINDOW_LEN * 100]\n",
    "\n",
    "        # print(key1, key2, key2 + WINDOW_LEN * 100)\n",
    "\n",
    "        X = df_sample.drop('label', axis=1).values\n",
    "        y = df_sample['label'].values[-1]\n",
    "\n",
    "        X = torch.Tensor(X)  # feat\n",
    "        y = torch.tensor(y).long()  # label last\n",
    "\n",
    "        return (X, y)  # shapeX= (3000,feat_num) shapey=(3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 数据集构建 ===================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68b8c039bd34039851d740836274968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='加载训练数据', max=5, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c018403c67a42f19555f99d6e61db2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='加载测试数据', max=2, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('=================== 数据集构建 ===================')\n",
    "\n",
    "train_dataset = MyDataset(root_dir=TRAIN_DIR, cls='训练')\n",
    "test_dataset = MyDataset(root_dir=TEST_DIR, cls='测试')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 10  # batch数据的大小\n",
    "# num_workers可能不支持\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True,num_workers=4)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True,num_workers=4)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "train_datalen, test_datalen = len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 模型类 ------------------------------\n",
    "\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size, batch_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # LSTM以word_embeddings作为输入, 输出维度为 hidden_dim 的隐藏状态值\n",
    "        # batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            batch_first=True, dropout=0.2)\n",
    "\n",
    "        # 线性层将隐藏状态空间映射到标注空间\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # 一开始并没有隐藏状态所以我们要先初始化一个\n",
    "        # 关于维度为什么这么设计请参考Pytoch相关文档\n",
    "        # 各个维度的含义是 (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, self.batch_size, self.hidden_dim).to(DEVICE),\n",
    "                torch.zeros(1, self.batch_size, self.hidden_dim).to(DEVICE))\n",
    "\n",
    "    def forward(self, embeds):\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        tag_scores = self.hidden2tag(lstm_out[:, -1, :])  # 取最后一个时刻的标签值\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 模型训练 ------------------------------\n",
    "\n",
    "EMBEDDING_DIM = len(FEAT_SELECT)\n",
    "HIDDEN_DIM = 20\n",
    "TAGSET_SIZE = 2\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, TAGSET_SIZE, BATCH_SIZE)\n",
    "model.to(DEVICE)  # GPU/CPU\n",
    "EPOCH = 20  # 训练周期\n",
    "# loss_function = nn.NLLLoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    best_model,best_auc=None,0 #保存最好的AUC和模型\n",
    "    print('=================== 模型训练/测试 ===================')\n",
    "    for epoch in range(EPOCH):\n",
    "        # -----------------epoch 训练----------------------\n",
    "        train_loss, train_pred, train_true = 0.0, [], []\n",
    "\n",
    "        for i, (X, y) in TQDM(enumerate(train_dataloader), desc='EPOCH-%d 训练' % epoch,\n",
    "                              total=len(train_dataloader)):\n",
    "        # for i, (X, y) in enumerate(train_dataloader):\n",
    "            model.train()  # 打开train模式\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)  # GPU/CPU\n",
    "            # Pytorch会累加梯度.我们需要在训练每个实例前清空梯度\n",
    "            model.zero_grad()\n",
    "            # 需要清空 LSTM 的隐状态,将其从上个实例的历史中分离出来.\n",
    "            model.hidden = model.init_hidden()\n",
    "            # 前向传播.\n",
    "            tag_scores = model(X)\n",
    "            # import ipdb\n",
    "            # ipdb.set_trace()\n",
    "            _, preds = tag_scores.max(1)\n",
    "            # 计算损失和梯度值, 通过调用 optimizer.step() 来更新梯度\n",
    "            loss = loss_function(tag_scores, y)\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            # 优化器\n",
    "            optimizer.step()\n",
    "            # 累加指标\n",
    "            train_loss += loss.item()\n",
    "            train_pred.extend(preds.tolist())\n",
    "            train_true.extend(y.tolist())\n",
    "\n",
    "            \n",
    "        loss = train_loss / len(train_dataset)        \n",
    "        train_auc = roc_auc_score(train_true, train_pred)\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        \n",
    "        \n",
    "        print('Train epoch:%d,Loss:%f, AUC: %f, ACC=%f' %(epoch, loss, train_auc, train_acc))\n",
    "        train_loss, train_pred, train_true = 0.0, [], []\n",
    "\n",
    "\n",
    "        # -----------------epoch 测试----------------------\n",
    "        model.eval()  # 打开eval模式\n",
    "        test_pred, test_true = [], []\n",
    "        with torch.no_grad():  # 不改变梯度\n",
    "            for i, (X, y) in TQDM(enumerate(test_dataloader), desc='EPOCH-%d 测试' % epoch,\n",
    "                                  total=len(test_dataloader)):\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)  # GPU/CPU\n",
    "                # 需要清空 LSTM 的隐状态,将其从上个实例的历史中分离出来.\n",
    "                model.hidden = model.init_hidden()\n",
    "                tag_scores = model(X)\n",
    "                _, preds = tag_scores.max(1)\n",
    "                test_pred.extend(preds.tolist())\n",
    "                test_true.extend(y.tolist())\n",
    "            test_auc = roc_auc_score(test_true, test_pred)\n",
    "            test_acc = accuracy_score(test_true, test_pred)\n",
    "            \n",
    "            \n",
    "            # auc更好时，保存更好的模型\n",
    "            if test_auc>best_auc:\n",
    "                best_auc=test_auc\n",
    "                best_model=model\n",
    "\n",
    "            # print(test_pred, test_true)\n",
    "            print('Test epoch:%d, AUC: %f, ACC=%f' % (epoch, test_auc, test_acc))\n",
    "        \n",
    "        # 一个epoch结束，数据记录\n",
    "        writer.add_scalar('train_loss', loss, epoch)\n",
    "        writer.add_scalars('AUC', {'train_auc':train_auc,\n",
    "                                   'test_auc':test_auc} , epoch)\n",
    "        writer.add_scalars('ACC', {'train_acc':train_acc,\n",
    "                                   'test_acc':test_acc} , epoch)\n",
    "\n",
    "    # 训练全部完成，打印best_auc，返回best_model\n",
    "    print('best Test AUC is:',best_auc)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 模型训练/测试 ===================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e286538d1f470ca1df9e9de2877f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EPOCH-0 训练', max=40, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch:0,Loss:0.047152, AUC: 0.728739, ACC=0.730000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65baa41351fe427ba0447e378ce5c6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EPOCH-0 测试', max=10, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch:0, AUC: 0.500000, ACC=0.500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2d753913f443a8ad6ff3674676128c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EPOCH-1 训练', max=40, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch:1,Loss:0.028257, AUC: 0.867912, ACC=0.867500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b86ae147384648a2374f1f615cc32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EPOCH-1 测试', max=10, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch:1, AUC: 0.530412, ACC=0.530000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9840891440bf4cee992633bc21a50929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EPOCH-2 训练', max=40, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ff868d3e265b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# 保存模型的方法（保存成二进制文件）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 再次读取模型的方法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model_reload=torch.load(open('best_model.pkl','rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-60fd44985481>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# 前向传播.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;31m# import ipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# ipdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-32211437e644>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeds)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 取最后一个时刻的标签值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model=train_model()\n",
    "# 保存模型的方法（保存成二进制文件）\n",
    "torch.save(best_model,open('best_model.pkl','wb'))\n",
    "# 再次读取模型的方法\n",
    "# model_reload=torch.load(open('best_model.pkl','rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
